{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data-preparation using PyCaret.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPTAXo40mlh2l6ZUyeiLF6w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaswataJash/kfpcomponent/blob/main/DataPreparationUsingPycaret/Data_preparation_using_PyCaret.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4orJiv6orBy",
        "outputId": "6ebaf774-9899-456a-d3ae-cc6f90edbeb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kfp==1.8.12"
      ],
      "metadata": {
        "id": "7vrY1cHoNxWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lus4TEd-8DbB",
        "outputId": "94793c0f-7781-4f3b-8349-0ace39479a8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycaret==2.3.10\n",
            "  Downloading pycaret-2.3.10-py3-none-any.whl (320 kB)\n",
            "\u001b[K     |████████████████████████████████| 320 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting lightgbm>=2.3.1\n",
            "  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 47.0 MB/s \n",
            "\u001b[?25hCollecting mlxtend>=0.17.0\n",
            "  Downloading mlxtend-0.19.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 49.2 MB/s \n",
            "\u001b[?25hCollecting mlflow\n",
            "  Downloading mlflow-1.26.0-py3-none-any.whl (17.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.8 MB 526 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from pycaret==2.3.10) (1.5.0)\n",
            "Requirement already satisfied: yellowbrick>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from pycaret==2.3.10) (1.4)\n",
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 42.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting kmodes>=0.10.1\n",
            "  Downloading kmodes-0.12.1-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pycaret==2.3.10) (1.3.5)\n",
            "Collecting Boruta\n",
            "  Downloading Boruta-0.3-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml<6.0.0 in /usr/local/lib/python3.7/dist-packages (from pycaret==2.3.10) (3.13)\n",
            "Collecting imbalanced-learn==0.7.0\n",
            "  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n",
            "\u001b[K     |████████████████████████████████| 167 kB 46.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pycaret==2.3.10) (3.2.5)\n",
            "Requirement already satisfied: plotly>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from pycaret==2.3.10) (5.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pycaret==2.3.10) (3.2.2)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from pycaret==2.3.10) (5.5.0)\n",
            "Collecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Collecting scikit-learn==0.23.2\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 45.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from pycaret==2.3.10) (7.7.0)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (from pycaret==2.3.10) (0.15.3)\n",
            "Collecting pyod\n",
            "  Downloading pyod-1.0.1.tar.gz (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 71.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<2.4.0 in /usr/local/lib/python3.7/dist-packages (from pycaret==2.3.10) (2.2.4)\n",
            "Requirement already satisfied: numba<0.55 in /usr/local/lib/python3.7/dist-packages (from pycaret==2.3.10) (0.51.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pycaret==2.3.10) (1.1.0)\n",
            "Collecting umap-learn\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim<4.0.0 in /usr/local/lib/python3.7/dist-packages (from pycaret==2.3.10) (3.6.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from pycaret==2.3.10) (0.11.2)\n",
            "Requirement already satisfied: scipy<=1.5.4 in /usr/local/lib/python3.7/dist-packages (from pycaret==2.3.10) (1.4.1)\n",
            "Requirement already satisfied: cufflinks>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pycaret==2.3.10) (0.17.3)\n",
            "Collecting pandas-profiling>=2.8.0\n",
            "  Downloading pandas_profiling-3.2.0-py2.py3-none-any.whl (262 kB)\n",
            "\u001b[K     |████████████████████████████████| 262 kB 56.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn==0.7.0->pycaret==2.3.10) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->pycaret==2.3.10) (3.1.0)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret==2.3.10) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret==2.3.10) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=34.4.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret==2.3.10) (57.4.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0.0->pycaret==2.3.10) (6.0.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret==2.3.10) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret==2.3.10) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret==2.3.10) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret==2.3.10) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret==2.3.10) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret==2.3.10) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret==2.3.10) (4.4.2)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret==2.3.10) (1.1.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret==2.3.10) (4.10.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret==2.3.10) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret==2.3.10) (3.6.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret==2.3.10) (5.3.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret==2.3.10) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret==2.3.10) (5.3.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->pycaret==2.3.10) (0.37.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret==2.3.10) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret==2.3.10) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret==2.3.10) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret==2.3.10) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->pycaret==2.3.10) (4.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret==2.3.10) (4.10.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret==2.3.10) (2.15.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret==2.3.10) (4.3.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->pycaret==2.3.10) (4.11.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->pycaret==2.3.10) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->pycaret==2.3.10) (21.4.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->pycaret==2.3.10) (5.7.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->pycaret==2.3.10) (3.8.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba<0.55->pycaret==2.3.10) (0.34.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pycaret==2.3.10) (2022.1)\n",
            "Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret==2.3.10) (2.11.3)\n",
            "Collecting phik>=0.11.1\n",
            "  Downloading phik-0.12.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (690 kB)\n",
            "\u001b[K     |████████████████████████████████| 690 kB 47.9 MB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0.0\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 58.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret==2.3.10) (0.5.1)\n",
            "Collecting tangled-up-in-unicode==0.2.0\n",
            "  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 43.3 MB/s \n",
            "\u001b[?25hCollecting multimethod>=1.4\n",
            "  Downloading multimethod-1.8-py3-none-any.whl (9.8 kB)\n",
            "Collecting markupsafe~=2.1.1\n",
            "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting visions[type_image_path]==0.7.4\n",
            "  Downloading visions-0.7.4-py3-none-any.whl (102 kB)\n",
            "\u001b[K     |████████████████████████████████| 102 kB 10.8 MB/s \n",
            "\u001b[?25hCollecting htmlmin>=0.1.12\n",
            "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret==2.3.10) (4.64.0)\n",
            "Collecting pydantic>=1.8.1\n",
            "  Downloading pydantic-1.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 34.9 MB/s \n",
            "\u001b[?25hCollecting requests>=2.24.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret==2.3.10) (2.6.3)\n",
            "Collecting imagehash\n",
            "  Downloading ImageHash-4.2.1.tar.gz (812 kB)\n",
            "\u001b[K     |████████████████████████████████| 812 kB 56.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret==2.3.10) (7.1.2)\n",
            "Collecting scipy<=1.5.4\n",
            "  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.4.1->pycaret==2.3.10) (8.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->pycaret==2.3.10) (0.2.5)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret==2.3.10) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret==2.3.10) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret==2.3.10) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret==2.3.10) (1.24.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret==2.3.10) (1.0.7)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret==2.3.10) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret==2.3.10) (3.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret==2.3.10) (2.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret==2.3.10) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret==2.3.10) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret==2.3.10) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret==2.3.10) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret==2.3.10) (0.9.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.3.10) (5.3.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.3.10) (1.8.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.3.10) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.3.10) (0.13.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->pycaret==2.3.10) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.3.10) (0.7.0)\n",
            "Collecting yellowbrick>=1.0.1\n",
            "  Downloading yellowbrick-1.3.post1-py3-none-any.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 66.2 MB/s \n",
            "\u001b[?25hCollecting numpy>=1.13.3\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 39.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from imagehash->visions[type_image_path]==0.7.4->pandas-profiling>=2.8.0->pycaret==2.3.10) (1.3.0)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 59.6 MB/s \n",
            "\u001b[?25hCollecting gitpython>=2.1.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 60.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret==2.3.10) (0.4)\n",
            "Collecting docker>=4.0.0\n",
            "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 55.1 MB/s \n",
            "\u001b[?25hCollecting gunicorn\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.1 MB/s \n",
            "\u001b[?25hCollecting databricks-cli>=0.8.7\n",
            "  Downloading databricks-cli-0.16.6.tar.gz (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 890 kB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret==2.3.10) (0.4.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret==2.3.10) (7.1.2)\n",
            "Collecting querystring-parser\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret==2.3.10) (1.3.0)\n",
            "Collecting prometheus-flask-exporter\n",
            "  Downloading prometheus_flask_exporter-0.20.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret==2.3.10) (3.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret==2.3.10) (21.3)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret==2.3.10) (1.1.4)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret==2.3.10) (1.4.36)\n",
            "Collecting pyjwt>=1.7.0\n",
            "  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow->pycaret==2.3.10) (3.2.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow->pycaret==2.3.10) (0.8.9)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow->pycaret==2.3.10) (1.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->pycaret==2.3.10) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->pycaret==2.3.10) (1.0.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.3.10) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.3.10) (5.0.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.3.10) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.3.10) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.3.10) (0.8.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret==2.3.10) (0.5.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow->pycaret==2.3.10) (0.14.1)\n",
            "Collecting funcy\n",
            "  Downloading funcy-1.17-py2.py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret==2.3.10) (2.8.1)\n",
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.3.0.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 50.9 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading pyLDAvis-3.2.2.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 47.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret==2.3.10) (0.16.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pyod->pycaret==2.3.10) (0.10.2)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod->pycaret==2.3.10) (0.5.2)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.7.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 58.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: htmlmin, imagehash, databricks-cli, pyLDAvis, pyod, umap-learn, pynndescent\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27098 sha256=0c1c90ceeb3f1660c8c22cc480f748befc32e628fc17b8c7318c6310eed171e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/e1/52/5b14d250ba868768823940c3229e9950d201a26d0bd3ee8655\n",
            "  Building wheel for imagehash (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imagehash: filename=ImageHash-4.2.1-py2.py3-none-any.whl size=295206 sha256=8bb63fc91adcc2e860e28e5f8c250022aa519930e7d9d550e4cc219084e3e54f\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/d5/59/5e3e297533ddb09407769762985d134135064c6831e29a914e\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.16.6-py3-none-any.whl size=112631 sha256=b03fe09c5a3546c138822fa2a29a7264f9eceeafbb7a1776593daa310a74c64b\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/c1/f8/d75a22e789ab6a4dff11f18338c3af4360189aa371295cc934\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-3.2.2-py2.py3-none-any.whl size=135617 sha256=b2797c25077444a2632f364830c53bb6c52db2899c44fe508dd54fc743e86319\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/b1/9b/560ac1931796b7303f7b517b949d2d31a4fbc512aad3b9f284\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-1.0.1-py3-none-any.whl size=147473 sha256=eea249ac68c47a1541b754ada832dd55d3113c7b77477868120fd3317d5811ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/c4/29/67ad87835b209f72e4706369c683741b09490f2829d64ea768\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82829 sha256=23f13fd104357f6f8e4c6f66b729ed4a51e73563c22547dd63b07d86bc8c1121\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/52/a5/1fd9e3e76a7ab34f134c07469cd6f16e27ef3a37aeff1fe821\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.7-py3-none-any.whl size=54286 sha256=4e8e4c6a7fc8a555f1effa108cd4317ad35e167148cb1f4f042ccb3345881e19\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/2a/f8/7bd5dcec71bd5c669f6f574db3113513696b98f3f9b51f496c\n",
            "Successfully built htmlmin imagehash databricks-cli pyLDAvis pyod umap-learn pynndescent\n",
            "Installing collected packages: markupsafe, numpy, tangled-up-in-unicode, smmap, scipy, multimethod, websocket-client, visions, scikit-learn, requests, pyjwt, Mako, imagehash, gitdb, querystring-parser, pyyaml, pynndescent, pydantic, prometheus-flask-exporter, phik, htmlmin, gunicorn, gitpython, funcy, docker, databricks-cli, alembic, yellowbrick, umap-learn, scikit-plot, pyod, pyLDAvis, pandas-profiling, mlxtend, mlflow, lightgbm, kmodes, imbalanced-learn, Boruta, pycaret\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: yellowbrick\n",
            "    Found existing installation: yellowbrick 1.4\n",
            "    Uninstalling yellowbrick-1.4:\n",
            "      Successfully uninstalled yellowbrick-1.4\n",
            "  Attempting uninstall: pandas-profiling\n",
            "    Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "  Attempting uninstall: mlxtend\n",
            "    Found existing installation: mlxtend 0.14.0\n",
            "    Uninstalling mlxtend-0.14.0:\n",
            "      Successfully uninstalled mlxtend-0.14.0\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Attempting uninstall: imbalanced-learn\n",
            "    Found existing installation: imbalanced-learn 0.8.1\n",
            "    Uninstalling imbalanced-learn-0.8.1:\n",
            "      Successfully uninstalled imbalanced-learn-0.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Boruta-0.3 Mako-1.2.0 alembic-1.7.7 databricks-cli-0.16.6 docker-5.0.3 funcy-1.17 gitdb-4.0.9 gitpython-3.1.27 gunicorn-20.1.0 htmlmin-0.1.12 imagehash-4.2.1 imbalanced-learn-0.7.0 kmodes-0.12.1 lightgbm-3.3.2 markupsafe-2.1.1 mlflow-1.26.0 mlxtend-0.19.0 multimethod-1.8 numpy-1.19.5 pandas-profiling-3.2.0 phik-0.12.2 prometheus-flask-exporter-0.20.1 pyLDAvis-3.2.2 pycaret-2.3.10 pydantic-1.9.0 pyjwt-2.4.0 pynndescent-0.5.7 pyod-1.0.1 pyyaml-5.4.1 querystring-parser-1.2.4 requests-2.27.1 scikit-learn-0.23.2 scikit-plot-0.3.7 scipy-1.5.4 smmap-5.0.0 tangled-up-in-unicode-0.2.0 umap-learn-0.5.3 visions-0.7.4 websocket-client-1.3.2 yellowbrick-1.3.post1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install pycaret==2.3.10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ref: https://github.com/pycaret/pycaret/issues/2490\n",
        "!pip install Jinja2==3.1.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKAa1jnEnDL3",
        "outputId": "19c97f93-c986-4d7f-fe58-7961166a27a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Jinja2==3.1.2\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▌                             | 10 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 20 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 40 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 51 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 81 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 92 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/dist-packages (from Jinja2==3.1.2) (2.1.1)\n",
            "Installing collected packages: Jinja2\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed Jinja2-3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://rclone.org/install.sh | sudo bash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I61CdpC5HywN",
        "outputId": "4f7fe15e-c825-4903-a434-5ad44d40cc74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  4497  100  4497    0     0   8453      0 --:--:-- --:--:-- --:--:--  8453\n",
            "Archive:  rclone-current-linux-amd64.zip\n",
            "   creating: tmp_unzip_dir_for_rclone/rclone-v1.58.1-linux-amd64/\n",
            "  inflating: tmp_unzip_dir_for_rclone/rclone-v1.58.1-linux-amd64/rclone  [binary]\n",
            "  inflating: tmp_unzip_dir_for_rclone/rclone-v1.58.1-linux-amd64/README.html  [text]  \n",
            "  inflating: tmp_unzip_dir_for_rclone/rclone-v1.58.1-linux-amd64/README.txt  [text]  \n",
            "  inflating: tmp_unzip_dir_for_rclone/rclone-v1.58.1-linux-amd64/git-log.txt  [text]  \n",
            "  inflating: tmp_unzip_dir_for_rclone/rclone-v1.58.1-linux-amd64/rclone.1  [text]  \n",
            "Purging old database entries in /usr/share/man...\n",
            "Processing manual pages under /usr/share/man...\n",
            "Purging old database entries in /usr/share/man/ko...\n",
            "Processing manual pages under /usr/share/man/ko...\n",
            "Purging old database entries in /usr/share/man/zh_CN...\n",
            "Processing manual pages under /usr/share/man/zh_CN...\n",
            "Purging old database entries in /usr/share/man/it...\n",
            "Processing manual pages under /usr/share/man/it...\n",
            "Purging old database entries in /usr/share/man/id...\n",
            "Processing manual pages under /usr/share/man/id...\n",
            "Purging old database entries in /usr/share/man/ja...\n",
            "Processing manual pages under /usr/share/man/ja...\n",
            "Purging old database entries in /usr/share/man/ru...\n",
            "Processing manual pages under /usr/share/man/ru...\n",
            "Purging old database entries in /usr/share/man/pt...\n",
            "Processing manual pages under /usr/share/man/pt...\n",
            "Purging old database entries in /usr/share/man/hu...\n",
            "Processing manual pages under /usr/share/man/hu...\n",
            "Purging old database entries in /usr/share/man/cs...\n",
            "Processing manual pages under /usr/share/man/cs...\n",
            "Purging old database entries in /usr/share/man/de...\n",
            "Processing manual pages under /usr/share/man/de...\n",
            "Purging old database entries in /usr/share/man/nl...\n",
            "Processing manual pages under /usr/share/man/nl...\n",
            "Purging old database entries in /usr/share/man/sv...\n",
            "Processing manual pages under /usr/share/man/sv...\n",
            "Purging old database entries in /usr/share/man/tr...\n",
            "Processing manual pages under /usr/share/man/tr...\n",
            "Purging old database entries in /usr/share/man/fi...\n",
            "Processing manual pages under /usr/share/man/fi...\n",
            "Purging old database entries in /usr/share/man/da...\n",
            "Processing manual pages under /usr/share/man/da...\n",
            "Purging old database entries in /usr/share/man/es...\n",
            "Processing manual pages under /usr/share/man/es...\n",
            "Purging old database entries in /usr/share/man/zh_TW...\n",
            "Processing manual pages under /usr/share/man/zh_TW...\n",
            "Purging old database entries in /usr/share/man/pl...\n",
            "Processing manual pages under /usr/share/man/pl...\n",
            "Purging old database entries in /usr/share/man/fr...\n",
            "Processing manual pages under /usr/share/man/fr...\n",
            "Purging old database entries in /usr/share/man/pt_BR...\n",
            "Processing manual pages under /usr/share/man/pt_BR...\n",
            "Purging old database entries in /usr/share/man/sr...\n",
            "Processing manual pages under /usr/share/man/sr...\n",
            "Processing manual pages under /usr/local/man...\n",
            "Updating index cache for path `/usr/local/man/man1'. Wait...done.\n",
            "Checking for stray cats under /usr/local/man...\n",
            "Checking for stray cats under /var/cache/man/oldlocal...\n",
            "1 man subdirectory contained newer manual pages.\n",
            "3 manual pages were added.\n",
            "0 stray cats were added.\n",
            "19 old database entries were purged.\n",
            "\n",
            "rclone v1.58.1 has successfully installed.\n",
            "Now run \"rclone config\" for setup. Check https://rclone.org/docs/ for more details.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"RCLONE_CONFIG_REMOTEREAD_TYPE\"] = 'http'\n",
        "os.environ[\"RCLONE_CONFIG_REMOTEREAD_URL\"] = 'https://raw.githubusercontent.com/pycaret/datasets/main/data/common/'\n",
        "\n",
        "## CREATE THE rclone read and write configuration file name as 'REMOTEREAD' and 'REMOTEWRITE'. Because the same are used within code.\n",
        "## So convention for creating any environment variables related to rclone should start either with 'RCLONE_CONFIG_REMOTEREAD' or 'RCLONE_CONFIG_REMOTEWRITE'\n",
        "\n",
        "#https://registry.opendata.aws/humor-detection/\n",
        "#os.environ[\"RCLONE_CONFIG_REMOTEREAD_TYPE\"] = 's3'\n",
        "#os.environ[\"RCLONE_CONFIG_REMOTEREAD_PROVIDER\"] = 'AWS'\n",
        "#os.environ[\"RCLONE_CONFIG_REMOTEREAD_ACCESS_KEY_ID\"] = ''\n",
        "#os.environ[\"RCLONE_CONFIG_REMOTEREAD_SECRET_ACCESS_KEY\"] = ''\n",
        "#os.environ[\"RCLONE_CONFIG_REMOTEREAD_REGION\"] = 'us-west-2' \n",
        "#os.environ[\"RCLONE_CONFIG_REMOTEREAD_ENDPOINT\"] = ''\n",
        "\n",
        "os.environ[\"RCLONE_CONFIG_REMOTEWRITE_TYPE\"] = 'local'\n",
        "os.environ[\"RCLONE_CONFIG_REMOTEWRITE_NOUNC\"] = 'true'\n",
        "\n",
        "#refer https://rclone.org/faq/#:~:text=Can%20I%20use%20rclone%20with,for%20services%20reached%20over%20https%20).\n",
        "#os.environ[\"http_proxy\"]=''\n",
        "#os.environ[\"https_proxy\"]=''\n",
        "#os.environ[\"HTTP_PROXY\"]=''\n",
        "#os.environ[\"HTTPS_PROXY\"]=''"
      ],
      "metadata": {
        "id": "lm_fuiVwg2S5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_datasource_directory_mountable = False\n",
        "#input_datasource_directory_to_be_mounted = 'humor-detection-pds/'\n",
        "#input_datasource_file_name = 'Non-humours-biased.csv'"
      ],
      "metadata": {
        "id": "1AIHBCxn30vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_preparation.py\n",
        "\n",
        "#!/usr/bin/env python3\n",
        "import argparse\n",
        "\n",
        "# Defining and parsing the command-line arguments\n",
        "parser = argparse.ArgumentParser(description='kubeflow pipeline component to read csv file and prepare the data')\n",
        "parser.add_argument('--input-datasource-directory-mountable', default=False, action=\"store_true\", help='whether input csv file is present in mountable remote location')\n",
        "parser.add_argument('--input-datasource-directory-to-be-mounted', type=str, help='if input-datasource-directory-mountable=True, name of the mountable directory (e.g. bucket name for s3)')\n",
        "parser.add_argument('--input-datasource-file-name', type=str, help='name of the csv file including file extension (if any)')\n",
        "parser.add_argument('--additional-options-csv-parsing', type=str, default= '{}', help='json formatted key-value pairs of strings which will be passed to pandas.read_csv()')\n",
        "parser.add_argument('--type-of-data-analysis-task', choices=['classification', 'regression', 'clustering', 'anomaly_detection'])\n",
        "parser.add_argument('--target-variable-name', type=str, help='for classification and regression, specify the column name holding target variable')\n",
        "parser.add_argument('--target-emptyindicator', type=str, default='', help='if target variable column holds null or na, those rows will be dropped. Sometime empty can be indicated by other representative string like - or *** etc')\n",
        "parser.add_argument('--generate-panda-dataframe-profiling-html', default=False, action=\"store_true\", help='whether to generate data-profile data for original and transformed dataframe (can be timeconsuming)')\n",
        "parser.add_argument('--data-preparations-options', type=str, default= '{}', help='json formatted key-value pairs of strings which will be passed to pycaret setup() function')\n",
        "parser.add_argument('--additional-options-csv-writing', type=str, default= '{}', help='json formatted key-value pairs of strings which will be passed to pandas.to_csv()')\n",
        "parser.add_argument('--output-datasource-directory-to-be-mounted', type=str, help='name of the mountable directory (e.g. bucket name for s3)')\n",
        "parser.add_argument('--output-datasource-file-name', type=str, help='filename of the prepared data')\n",
        "args = parser.parse_args()\n",
        "\n",
        "import tempfile\n",
        "local_datastore_read_dir = tempfile.mkdtemp(prefix=\"my_local_read-\")\n",
        "print('local_datastore_read_dir:',local_datastore_read_dir)\n",
        "\n",
        "local_datastore_write_dir = tempfile.mkdtemp(prefix=\"my_local_write-\")\n",
        "print('local_datastore_write_dir:',local_datastore_write_dir)\n",
        "\n",
        "#input file handling\n",
        "import subprocess\n",
        "import os\n",
        "import sys\n",
        "if args.input_datasource_directory_mountable:\n",
        "    input_data_read_cmd = \"rclone -v mount remoteread:\" + args.input_datasource_directory_to_be_mounted + ' ' + local_datastore_read_dir + ' --daemon'\n",
        "else:\n",
        "    input_data_read_cmd = \"rclone -v copy remoteread:\" + args.input_datasource_file_name + ' ' + local_datastore_read_dir\n",
        "input_data_read_call = subprocess.run(input_data_read_cmd.split(), stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "print(input_data_read_call.stdout)\n",
        "if input_data_read_call.returncode != 0:\n",
        "    print(\"Error in rclone, errorcode=\", input_data_read_call.returncode)\n",
        "    sys.stdout.flush()\n",
        "    sys.exit(\"Forceful exit as rclone returned error in context of reading\")\n",
        "\n",
        "#output file handling\n",
        "output_data_write_cmd = \"rclone -v mount remotewrite:\" + args.output_datasource_directory_to_be_mounted + ' ' + local_datastore_write_dir + ' --daemon'\n",
        "output_data_write_call = subprocess.run(output_data_write_cmd.split(), stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "print(output_data_write_call.stdout)\n",
        "if output_data_write_call.returncode != 0:\n",
        "    print(\"Error in rclone, errorcode=\", output_data_write_call.returncode)\n",
        "    sys.stdout.flush()\n",
        "    sys.exit(\"Forceful exit as rclone returned error in context of writing\")\n",
        "\n",
        "#handling input csv file reading\n",
        "import pandas\n",
        "import json\n",
        "from pandas_profiling import ProfileReport\n",
        "try:\n",
        "    parse_config = json.loads(args.additional_options_csv_parsing)\n",
        "    print('parse_config = (', type(parse_config), ')', parse_config)\n",
        "    parse_config['filepath_or_buffer'] = os.path.join(local_datastore_read_dir,args.input_datasource_file_name)\n",
        "    my_data = pandas.read_csv(**parse_config)\n",
        "    if args.generate_panda_dataframe_profiling_html:\n",
        "        original_profile = ProfileReport(my_data, title=\"Original dataframe\", explorative=True)\n",
        "        original_profile.to_file(\"original_data_report.html\")\n",
        "    print(my_data)\n",
        "    \n",
        "except BaseException as err:\n",
        "    print(\"Error=\", err, ' ', type(err))\n",
        "    sys.stdout.flush()\n",
        "    sys.exit(\"Forceful exit as exception encountered while parsing input csv file\")\n",
        "\n",
        "#handling data preprocessing\n",
        "import pycaret\n",
        "try:\n",
        "    if os.path.exists(\"logs.log\"):\n",
        "        os.remove(\"logs.log\") #removing any content from log which pycaret will internally use for its own logging\n",
        "    print('pycaret version = ', pycaret.utils.version())\n",
        "    setup_config = json.loads(args.data_preparations_options)\n",
        "    print('setup_config = (', type(setup_config), ')', setup_config)\n",
        "    if args.type_of_data_analysis_task == 'classification':\n",
        "        import pycaret.classification\n",
        "        setup_fn = pycaret.classification.setup\n",
        "        get_config_fn = pycaret.classification.get_config\n",
        "        setup_config['target'] = args.target_variable_name\n",
        "        \n",
        "    elif args.type_of_data_analysis_task == 'regression':\n",
        "        import pycaret.regression\n",
        "        setup_fn = pycaret.regression.setup\n",
        "        get_config_fn = pycaret.regression.get_config\n",
        "        setup_config['target'] = args.target_variable_name\n",
        "\n",
        "    elif args.type_of_data_analysis_task == 'clustering':\n",
        "        import pycaret.clustering\n",
        "        setup_fn = pycaret.clustering.setup\n",
        "        get_config_fn = pycaret.clustering.get_config\n",
        "\n",
        "    elif args.type_of_data_analysis_task == 'anomaly':\n",
        "        import pycaret.anomaly\n",
        "        setup_fn = pycaret.anomaly.setup\n",
        "        get_config_fn = pycaret.anomaly.get_config\n",
        "        \n",
        "    #as part of pycaret's data cleaning the rows with target column = nan are not being cleaned up. Thus, cleaning those rows explicitely\n",
        "    if len(args.target_emptyindicator) > 0:\n",
        "        #ref: https://stackoverflow.com/questions/49291740/delete-rows-if-there-are-null-values-in-a-specific-column-in-pandas-dataframe\n",
        "        import numpy as np\n",
        "        my_data[args.target_variable_name] = my_data[args.target_variable_name].replace(args.target_emptyindicator, np.nan)\n",
        "        my_data = my_data.dropna(axis=0, subset=[args.target_variable_name])\n",
        "\n",
        "    setup_config['data'] = my_data\n",
        "    setup_config['log_experiment'] = False\n",
        "    setup_config['data_split_shuffle'] = False\n",
        "    setup_config['html'] = False\n",
        "    setup_config['silent'] = True\n",
        "    setup_fn(**setup_config)\n",
        "    #ref: https://www.kdnuggets.com/2020/11/5-things-doing-wrong-pycaret.html\n",
        "    X_transformed = get_config_fn('X')\n",
        "    my_transformed_data = X_transformed\n",
        "    if args.type_of_data_analysis_task == 'classification' or args.type_of_data_analysis_task == 'regression':\n",
        "        y_transformed = get_config_fn('y')\n",
        "        my_transformed_data = X_transformed.merge(y_transformed,left_index=True, right_index=True)\n",
        "    print(my_transformed_data)\n",
        "\n",
        "    pycaret.utils.get_system_logs() #this will print the pycaret's own log into console\n",
        "\n",
        "    if args.generate_panda_dataframe_profiling_html:\n",
        "        transformed_profile = ProfileReport(my_transformed_data, title=\"Transformed dataframe\", explorative=True)\n",
        "        transformed_profile.to_file(\"transformed_data_report.html\")\n",
        "    \n",
        "except BaseException as err:\n",
        "    pycaret.utils.get_system_logs()\n",
        "    print(\"Error=\", err, ' ', type(err))\n",
        "    sys.stdout.flush()\n",
        "    sys.exit(\"Forceful exit as exception encountered while transforming input dataframe\")\n",
        "\n",
        "#handling output csv file writing\n",
        "try:\n",
        "    to_csv_config = json.loads(args.additional_options_csv_writing)\n",
        "    print('to_csv_config = (', type(to_csv_config), ')', to_csv_config)\n",
        "    to_csv_config['path_or_buf'] = os.path.join(local_datastore_write_dir,args.output_datasource_file_name)\n",
        "    my_transformed_data.to_csv(**to_csv_config)\n",
        "except BaseException as err:\n",
        "    print(\"Error=\", err, ' ', type(err))\n",
        "    sys.stdout.flush()\n",
        "    sys.exit(\"Forceful exit as exception encountered while trying to write prepared data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU9Vh7P4P4_h",
        "outputId": "2a8874e9-8f42-4c49-a503-6ed611c3d312"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data_preparation.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python data_preparation.py --input-datasource-file-name 'CTG.csv' --additional-options-csv-parsing '{\"sep\":\",\" , \"header\":0}' \\\n",
        "    --type-of-data-analysis-task 'classification' --target-variable-name 'NSP' \\\n",
        "    --data-preparations-options '{\"ignore_low_variance\":true, \"remove_outliers\":true, \"remove_multicollinearity\":true, \"multicollinearity_threshold\":0.7}' \\\n",
        "    --output-datasource-directory-to-be-mounted '/content' --output-datasource-file-name 'CTG_data-prep.csv'"
      ],
      "metadata": {
        "id": "5i9h_W3T4H87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Dockerfile\n",
        "\n",
        "FROM python:3.7\n",
        "RUN python3 -m pip install pycaret==2.3.10\n",
        "RUN python3 -m pip install Jinja2==3.1.2\n",
        "RUN curl https://rclone.org/install.sh | bash\n",
        "\n",
        "COPY data_preparation.py /tmp"
      ],
      "metadata": {
        "id": "hk00hb780Qo_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc119727-6325-4dab-8aa6-7fc4cfb74ab8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Dockerfile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before commiting code to github, install github client (gh) by following instruction mentioned in https://github.com/cli/cli/blob/trunk/docs/install_linux.md\n",
        "\n",
        "Use the colab's 'Terminal' icon present in left vertical pane to open linux terminal to type commands. Once 'gh' is installed, type **$gh auth login** (refer https://docs.github.com/en/get-started/getting-started-with-git/caching-your-github-credentials-in-git) to follow onscreen prompts. For colab, use **pasting of personal token** option. Personal tokens can be generated in https://github.com/settings/tokens"
      ],
      "metadata": {
        "id": "2Nix3R2joPdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git config --list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1YZYfVfJoAB",
        "outputId": "72e47fd7-c1ce-4839-f66d-293faa843038"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user.email=29448766+ShaswataJash@users.noreply.github.com\n",
            "user.name=ShaswataJash\n",
            "credential.https://github.com.helper=\n",
            "credential.https://github.com.helper=!/usr/bin/gh auth git-credential\n",
            "credential.https://gist.github.com.helper=\n",
            "credential.https://gist.github.com.helper=!/usr/bin/gh auth git-credential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -Rf kfpcomponent"
      ],
      "metadata": {
        "id": "JVc_RmC9MrgG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ShaswataJash/kfpcomponent.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5LCKX0SXUxs",
        "outputId": "bd6fd7d1-f6b3-42ec-e303-2638fa3a2bd9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'kfpcomponent'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir kfpcomponent/DataPreparationUsingPycaret"
      ],
      "metadata": {
        "id": "PWT-29j1XYhi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rsync -c data_preparation.py kfpcomponent/DataPreparationUsingPycaret/"
      ],
      "metadata": {
        "id": "n3b7gcGhXde6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rsync -c Dockerfile kfpcomponent/DataPreparationUsingPycaret/"
      ],
      "metadata": {
        "id": "10N6bInqXgii"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd kfpcomponent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RUDYMnmXlIW",
        "outputId": "4539cec4-ad81-4efe-adc8-731eb412e48c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/kfpcomponent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add -A"
      ],
      "metadata": {
        "id": "iAyaTjClX9S0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW4fzKBsYCGO",
        "outputId": "c436de87-3a94-43ab-d800-ac870e6ed167"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes to be committed:\n",
            "  (use \"git reset HEAD <file>...\" to unstage)\n",
            "\n",
            "\t\u001b[32mnew file:   DataPreparationUsingPycaret/Dockerfile\u001b[m\n",
            "\t\u001b[32mnew file:   DataPreparationUsingPycaret/data_preparation.py\u001b[m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -a -m \"my first commit\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbaNqafyYHV7",
        "outputId": "c175ebb5-d7ad-455b-8d66-99f169d026fb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 5913d45] my first commit\n",
            " 2 files changed, 150 insertions(+)\n",
            " create mode 100644 DataPreparationUsingPycaret/Dockerfile\n",
            " create mode 100644 DataPreparationUsingPycaret/data_preparation.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLZfkrleaqQ3",
        "outputId": "1ce37306-56f7-47b4-ddee-9821b51a01d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counting objects: 5, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects:  20% (1/5)   \rCompressing objects:  40% (2/5)   \rCompressing objects:  60% (3/5)   \rCompressing objects:  80% (4/5)   \rCompressing objects: 100% (5/5)   \rCompressing objects: 100% (5/5), done.\n",
            "Writing objects:  20% (1/5)   \rWriting objects:  40% (2/5)   \rWriting objects:  60% (3/5)   \rWriting objects:  80% (4/5)   \rWriting objects: 100% (5/5)   \rWriting objects: 100% (5/5), 2.73 KiB | 2.73 MiB/s, done.\n",
            "Total 5 (delta 0), reused 0 (delta 0)\n",
            "To https://github.com/ShaswataJash/kfpcomponent.git\n",
            "   ba1baf3..5913d45  main -> main\n"
          ]
        }
      ]
    }
  ]
}